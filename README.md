# Spark-Snowflake-In-JupyterNotebook
This project showcases a data pipeline that integrates Snowflake and Spark to analyze retail sales data. It uses Snowflake's sample datasets and Spark for data processing, enabling insights that address common challenges in the retail industry, using Jupyter Notebook

## How to Replicate

1. Clone this repository:
   ```bash
   git clone https://github.com/garideli/Spark-Snowflake-In-JupyterNotebook.git
   cd Spark-Snowflake-In-JupyterNotebook

2.	Set up a .env file in the root directory with the following content:
ENV_PATH=/absolute/path/to/.env
SNOWFLAKE_USER=your_snowflake_username
SNOWFLAKE_PASSWORD=your_snowflake_password

3.	Install dependencies and run the notebook:
pip install -r requirements.txt
jupyter notebook retail_sales_analysis.ipynb

4.	Run each cell in the notebook using Ctrl+Enter.






